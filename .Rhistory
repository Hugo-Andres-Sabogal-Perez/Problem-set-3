library(rio)
library(tidyverse)
require(sf)
require(leaflet)
require(osmdata)
library(raster)
library(stringr)
primary<-obtener_osmdata('highway', 'primary', 'linea')
obtener_osmdata<-function(llave, valor, tipo_dato){
### Utilizamoas osm para bogota
data <- opq(bbox = getbb("Bogotá Colombia")) %>%
add_osm_feature(key = llave , value = valor)
# cambios el tipo de objeto
data<- osmdata_sf(data)
# dejamos poligonos y name y id
if (tipo_dato=='linea'){
data <- data$osm_lines %>%
dplyr::select(osm_id, name)
}
else if (tipo_dato=='puntos'){
data <- data$osm_points %>%
dplyr::select(osm_id, name)
}
else if (tipo_dato=='poligono'){
data <- data$osm_polygons %>%
dplyr::select(osm_id, name)
}
# Convertimos a tipo de objeto sf
data<-st_as_sf(data)
return(data)
}
primary<-obtener_osmdata('highway', 'primary', 'linea')
primary<- st_cast(primary, "POINT")
sf_use_s2(FALSE) ### Linea necesaria pára correr el codigo
primary<- st_cast(primary, "POINT")
leaflet() %>%
addTiles() %>%
addPolylines(data = primary)
View(primary)
require(leaflet)
leaflet() %>%
addTiles() %>%
addCircles(data = primary)
motorway<-obtener_osmdata('highway', 'motorway', 'linea')
motorway<- st_cast(primary, "POINT")
#
##Trunk (avenida caracas)
motorway<-obtener_osmdata('highway', 'trunk', 'linea')
motorway<- st_cast(primary, "POINT")
primary<-obtener_osmdata('highway', 'primary', 'linea')
primary<- st_cast(primary, "POINT")
#motorway (autopiesta norte)
motorway<-obtener_osmdata('highway', 'motorway', 'linea')
motorway<- st_cast(primary, "POINT")
#
##Trunk (avenida caracas)
trunk<-obtener_osmdata('highway', 'trunk', 'linea')
trunk<- st_cast(primary, "POINT")
View(motorway)
primary<- rbind(primary,motorway, trunk)
leaflet() %>%
addTiles() %>%
addCircles(data = primary)
leaflet() %>%
addTiles() %>%
addCircles(data = trunk)
primary<-obtener_osmdata('highway', 'primary', 'linea')
primary<- st_cast(primary, "POINT")
#motorway (autopiesta norte)
motorway<-obtener_osmdata('highway', 'motorway', 'linea')
motorway<- st_cast(motorway, "POINT")
#
##Trunk (avenida caracas)
trunk<-obtener_osmdata('highway', 'trunk', 'linea')
trunk<- st_cast(trunk, "POINT")
leaflet() %>%
addTiles() %>%
addCircles(data = trunk)
leaflet() %>%
addTiles() %>%
addCircles(data = motorway)
motorway<-obtener_osmdata('highway', 'motorway', 'linea')
leaflet() %>%
addTiles() %>%
addCircles(data = motorway)
leaflet() %>%
addTiles() %>%
addPolylines(data = motorway)
trunk<-obtener_osmdata('highway', 'trunk', 'linea')
trunk<-obtener_osmdata('highway', 'trunk', 'linea')
leaflet() %>%
addTiles() %>%
addPolylines(data = trunk)
primary<-obtener_osmdata('highway', 'primary', 'linea')
primary<- st_cast(primary, "POINT")
##Trunk (avenida caracas, NQS y automista norte y sur)
trunk<-obtener_osmdata('highway', 'trunk', 'linea')
trunk<- st_cast(trunk, "POINT")
primary<- rbind(primary, trunk)
leaflet() %>%
addTiles() %>%
addPolylines(data = primary)
class(primary)
View(primary)
leaflet() %>%
addTiles() %>%
addCircles(data = primary)
train_su<-import('Stores/inputs/train.csv')
#### Modelos predictivos ####
########## Modelos predictivos ######
#Set directory
setwd(substr(getwd(), 1, nchar(getwd()) - 8))
#limpiar en entorno
rm(list = ls())
###Librerias
library(pacman)
p_load(tidyverse, # Manipular dataframes
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # Modelado de datos limpios y ordenados
rattle, # Interfaz gráfica para el modelado de datos
spatialsample, # Muestreo espacial para modelos de aprendizaje automático
glmnet)
###Improtamos datos y los convertimos a sf
train<-import('Stores/outputs/train_modelos.rds')
test<-import('Stores/outputs/test_modelos.rds')
train<- st_as_sf(train)
###Alistamos lo folds
set.seed(10001)
block_folds <- spatial_block_cv(train, v = 5)
autoplot(block_folds)
## Eliminamos geometry
train<- as.data.frame(train)
train<- train %>% select(-geometry,-nombre_sector)
test<- as.data.frame(test)
test<- test %>% select(-geometry)
### configuramos tidymodels (receta)
rec_1 <- recipe(ln_price ~ . , data = train) %>%
step_dummy(all_nominal_predictors()) %>%  # crea dummies para las variables categóricas
step_zv(all_predictors()) %>%   #  elimina predictores con varianza cero (constantes)
step_normalize(all_predictors())  # normaliza los predictores.
### creamos specificación
reg_lineal <- linear_reg() %>% set_engine("lm")
### Configuramos flujo de trabajo
workflow_1 <- workflow() %>%
# Agregar la receta de preprocesamiento de datos. En este caso la receta 1
add_recipe(rec_1) %>%
# Agregar la especificación del modelo de regresión Elastic Net
add_model(reg_lineal)
### configuramos modelos
set.seed(10001)
tune_res1 <- tune_grid(
workflow_1,         # El flujo de trabajo que contiene: receta y especificación del modelo
resamples = block_folds,  # Folds de validación cruzada espacial
metrics = metric_set(mae), # metrica
)
### ver resultado
collect_metrics(tune_res1)
### Mejor metrica (en este caso es lm entonces no hay hiperparametros)
best_tune<- select_best(tune_res1, metric = "mae")
###Finalizamos flujo
res1_final <- finalize_workflow(workflow_1, best_tune)
#Sacamos los coef (para el caso de regression)
reg_coef <- fit(res1_final, data = train)
## Creamos submiission
pred1_ln<- predict(reg_coef,test)
View(pred1_ln)
View(reg_lineal)
class(pred1_ln)
pred1_ln<-as.vector( predict(reg_coef,test))
View(pred1_ln)
pred1_ln[[".pred"]]
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-pred1_ln[[1]]
#limpiar en entorno
rm(list = ls())
###Librerias
library(pacman)
p_load(tidyverse, # Manipular dataframes
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # Modelado de datos limpios y ordenados
rattle, # Interfaz gráfica para el modelado de datos
spatialsample, # Muestreo espacial para modelos de aprendizaje automático
glmnet)
###Improtamos datos y los convertimos a sf
train<-import('Stores/outputs/train_modelos.rds')
test<-import('Stores/outputs/test_modelos.rds')
train<- st_as_sf(train)
###Alistamos lo folds
set.seed(10001)
block_folds <- spatial_block_cv(train, v = 5)
autoplot(block_folds)
## Eliminamos geometry
train<- as.data.frame(train)
train<- train %>% select(-geometry,-nombre_sector)
test<- as.data.frame(test)
test<- test %>% select(-geometry)
### configuramos tidymodels (receta)
rec_1 <- recipe(ln_price ~ . , data = train) %>%
step_dummy(all_nominal_predictors()) %>%  # crea dummies para las variables categóricas
step_zv(all_predictors()) %>%   #  elimina predictores con varianza cero (constantes)
step_normalize(all_predictors())  # normaliza los predictores.
### creamos specificación
reg_lineal <- linear_reg() %>% set_engine("lm")
### Configuramos flujo de trabajo
workflow_1 <- workflow() %>%
# Agregar la receta de preprocesamiento de datos. En este caso la receta 1
add_recipe(rec_1) %>%
# Agregar la especificación del modelo de regresión Elastic Net
add_model(reg_lineal)
### configuramos modelos
set.seed(10001)
tune_res1 <- tune_grid(
workflow_1,         # El flujo de trabajo que contiene: receta y especificación del modelo
resamples = block_folds,  # Folds de validación cruzada espacial
metrics = metric_set(mae), # metrica
)
### ver resultado
collect_metrics(tune_res1)
### Mejor metrica (en este caso es lm entonces no hay hiperparametros)
best_tune<- select_best(tune_res1, metric = "mae")
###Finalizamos flujo
res1_final <- finalize_workflow(workflow_1, best_tune)
#Sacamos los coef (para el caso de regression)
reg_coef <- fit(res1_final, data = train)
## Creamos submiission
pred1_ln<-as.vector(predict(reg_coef,test))
pred1_ln<-pred1_ln[[1]]
sub1<- test %>% mutate(price=exp(pred1_ln))  %>%
mutate(price=round(price))  %>%
select(property_id, price)
View(sub1)
View(sub1)
export(sub, 'Stores/submits/reg_lineal.csv')
View(sub1)
export(sub1, 'Stores/submits/reg_lineal.csv')
rm(list = ls())
###Librerias
library(pacman)
p_load(tidyverse, # Manipular dataframes
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # Modelado de datos limpios y ordenados
rattle, # Interfaz gráfica para el modelado de datos
spatialsample, # Muestreo espacial para modelos de aprendizaje automático
ranger)
p_load(tidyverse, # Manipular dataframes
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # Modelado de datos limpios y ordenados
rattle, # Interfaz gráfica para el modelado de datos
spatialsample, # Muestreo espacial para modelos de aprendizaje automático
ranger,
rpart)
workflow_2 <- workflow() %>%
# Agregar la receta de preprocesamiento de datos. En este caso la receta 1
add_recipe(rec_1) %>%
# Agregar la especificación del modelo de regresión Elastic Net
add_model(cart)
cart<-decision_tree(mode = "regression") %>%set_engine(engine = "rpart")
##workflow 2
workflow_2 <- workflow() %>%
# Agregar la receta de preprocesamiento de datos. En este caso la receta 1
add_recipe(rec_1) %>%
# Agregar la especificación del modelo de regresión Elastic Net
add_model(cart)
#### Modelos predictivos ####
########## Modelos predictivos ######
#Set directory
setwd(substr(getwd(), 1, nchar(getwd()) - 8))
#limpiar en entorno
rm(list = ls())
###Librerias
library(pacman)
p_load(tidyverse, # Manipular dataframes
rio, # Importar datos fácilmente
sf, # Leer/escribir/manipular datos espaciales
tidymodels, # Modelado de datos limpios y ordenados
rattle, # Interfaz gráfica para el modelado de datos
spatialsample, # Muestreo espacial para modelos de aprendizaje automático
ranger,
rpart)
###Improtamos datos y los convertimos a sf
train<-import('Stores/outputs/train_modelos.rds')
test<-import('Stores/outputs/test_modelos.rds')
train<- st_as_sf(train)
###Alistamos lo folds
set.seed(10001)
block_folds <- spatial_block_cv(train, v = 5)
autoplot(block_folds)
## Eliminamos geometry
train<- as.data.frame(train)
train<- train %>% select(-geometry,-nombre_sector)
test<- as.data.frame(test)
test<- test %>% select(-geometry)
### configuramos tidymodels (receta)
rec_1 <- recipe(ln_price ~ . , data = train) %>%
step_dummy(all_nominal_predictors()) %>%  # crea dummies para las variables categóricas
step_zv(all_predictors()) %>%   #  elimina predictores con varianza cero (constantes)
step_normalize(all_predictors())  # normaliza los predictores.
cart<-decision_tree(mode = "regression") %>%set_engine(engine = "rpart")
##workflow 2
workflow_2 <- workflow() %>%
# Agregar la receta de preprocesamiento de datos. En este caso la receta 1
add_recipe(rec_1) %>%
# Agregar la especificación del modelo de regresión Elastic Net
add_model(cart)
grid_cart<- expand.grid(cp = seq(0, 0.03, 0.00001))
tune_res1 <- tune_grid(
workflow_2,         # El flujo de trabajo que contiene: receta y especificación del modelo
resamples = block_folds,  # Folds de validación cruzada espacial
metrics = metric_set(mae), # metrica
grid=grid_cart)
